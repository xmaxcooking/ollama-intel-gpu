services:
  ollama-intel-gpu:
    build:
      context: .
      dockerfile: Dockerfile 
    ports:
      - 11434:11434
    devices:
      - /dev/dri:/dev/dri
    cpus: '6'
    mem_limit: 12G
    environment:
      - TZ=Europe/Berlin
      - DEVICE=Arc
    volumes:
      - ollama-intel-gpu:/root/.ollama
    security_opt:
      - no-new-privileges:true
    restart: unless-stopped
      
  ollama-webui:
    image: ghcr.io/open-webui/open-webui 
    ports:
      - 9090:8080/tcp
    environment:
      - TZ=Europe/Berlin
      - OLLAMA_BASE_URL=http://ollama-intel-gpu:11434
    volumes:
      - ollama-webui:/app/backend/data
    depends_on:
      - ollama-intel-gpu
    restart: unless-stopped
    
volumes:
  ollama:
    driver: local
  ui:
    driver: local
